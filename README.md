# ðŸ§  SkipGram-WordEmbeddings-NLP

**A compact end-to-end NLP pipeline for legal judgement summarization.**

This repository implements **OCR-based PDF preprocessing**, **Skip-Gram word-embedding training from scratch (NumPy only)**, and both **extractive** and **rule-based abstractive summarization**.  

The **abstractive summary** is generated by refining the extractive summary using **POS tagging**, **NER**, and **frequency analysis** to identify key subjects, actions, and descriptors, then merging redundant phrases for a concise, fluent result.


---

## Project Overview

### Goal
Build a **reproducible pipeline** that:

1. Extracts text from PDF court judgments using OCR  
2. Cleans and splits text into sentences  
3. Merges and prepares dataset (JSON / JSONL) for training  
4. Trains a **Skip-Gram neural language model (NumPy)** to learn word embeddings  
5. Produces:
   - **Extractive summaries** (sentence ranking via cosine similarity)  
   - **Short rule-based abstractive summary** derived from extractive output

### Constraints
- **No pretrained models or third-party embedding libraries**  
  (No Hugging Face, Gensim, Word2Vec, Sentence-Transformers)
- **Allowed libraries**:  
  `numpy`, `nltk`, `spacy`, `pandas`, `pdf2image`, `pytesseract`, `Pillow`, standard Python libs

---

## Quick Start â€” Requirements

```bash
Python 3.8+
```

#### Install required packages:
```bash
pip install numpy pandas nltk spacy pdf2image pytesseract pillow
python -m spacy download en_core_web_sm
```

## Step-by-Step: Run the Pipeline

Run commands from the repository root. 

####  1. OCR + Extract Text from PDFs
```bash
python "Data Preprocessing/Extracting_data_from_pdfs.py"
```

####  2. Merge Multiple JSON Outputs (Optional)
```bash
python "Data Preprocessing/merge_jsonl_script.py"
```

#### 3. Preprocess for Skip-Gram Training
```bash
python "Model implementation/preprocess_and_save.py"
```

#### 4. Train Skip-Gram Model (NumPy) & Save
```bash
python "Model implementation/train_skipgram_with_minibatch.py"
```

#### 5. Generate Extractive & Abstractive Summaries

#### Function: 

summarize_with_model(jsonl_file, model_path)

#### File: 

train_skipgram_with_minibatch.py


Example Usage (Python REPL or script):


```bash
from train_skipgram_with_minibatch import summarize_with_model

summarize_with_model('test.jsonl', 'skipgram_model_lr0.3_bs16.pkl')
```

#### Steps:

1. Load model & word2idx

2. Compute sentence embeddings (avg of word embeddings W1)

3. Build document embedding (mean of sentence embeddings)

4. Rank sentences by cosine similarity â†’ extractive summary

5. Use spaCy rule engine â†’ short abstractive summary
